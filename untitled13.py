# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-4eJdi1gLqAjwhNZuh3Q3_ELvgCv2aV_
"""

# ==========================================
# 2. IMPLEMENTAZIONE KERNEL CUDA (FORWARD & BACKWARD)
# ==========================================
cpp_source = """
torch::Tensor nova_cuda_forward(torch::Tensor x, float beta);
torch::Tensor nova_cuda_backward(torch::Tensor grad_output, torch::Tensor x, float beta);
"""

cuda_source = """
#include <torch/extension.h>
#include <cuda.h>
#include <cuda_runtime.h>

template <typename scalar_t>
__global__ void nova_cuda_forward_kernel(const scalar_t* __restrict__ x, scalar_t* __restrict__ out, const float beta, const int size) {
    const int index = blockIdx.x * blockDim.x + threadIdx.x;
    if (index < size) {
        const scalar_t val = x[index];
        const scalar_t bx = beta * val;
        const float sig = 1.0f / (1.0f + expf(-static_cast<float>(bx)));
        const scalar_t gating = val * static_cast<scalar_t>(sig);
        const scalar_t rational = val / (1.0f + bx * bx);
        out[index] = gating - rational;
    }
}

template <typename scalar_t>
__global__ void nova_cuda_backward_kernel(const scalar_t* __restrict__ grad_output, const scalar_t* __restrict__ x, scalar_t* __restrict__ grad_input, const float beta, const int size) {
    const int index = blockIdx.x * blockDim.x + threadIdx.x;
    if (index < size) {
        const scalar_t val = x[index];
        const scalar_t bx = beta * val;
        const float sig = 1.0f / (1.0f + expf(-static_cast<float>(bx)));
        const float sig_deriv = sig * (1.0f - sig);
        const scalar_t d_gating = static_cast<scalar_t>(sig + static_cast<float>(bx) * sig_deriv);
        const float bx_sq = static_cast<float>(bx * bx);
        const float denom = 1.0f + bx_sq;
        const scalar_t d_rational = static_cast<scalar_t>((1.0f - bx_sq) / (denom * denom));
        const scalar_t grad_val = d_gating - d_rational;
        grad_input[index] = grad_output[index] * grad_val;
    }
}

torch::Tensor nova_cuda_forward(torch::Tensor x, float beta) {
    auto out = torch::empty_like(x);
    const int threads = 256;
    const int blocks = (x.numel() + threads - 1) / threads;
    AT_DISPATCH_FLOATING_TYPES(x.scalar_type(), "nova_forward_cuda", ([&] {
        nova_cuda_forward_kernel<scalar_t><<<blocks, threads>>>(x.data_ptr<scalar_t>(), out.data_ptr<scalar_t>(), beta, x.numel());
    }));
    return out;
}

torch::Tensor nova_cuda_backward(torch::Tensor grad_output, torch::Tensor x, float beta) {
    auto grad_input = torch::empty_like(x);
    const int threads = 256;
    const int blocks = (x.numel() + threads - 1) / threads;
    AT_DISPATCH_FLOATING_TYPES(x.scalar_type(), "nova_backward_cuda", ([&] {
        nova_cuda_backward_kernel<scalar_t><<<blocks, threads>>>(grad_output.data_ptr<scalar_t>(), x.data_ptr<scalar_t>(), grad_input.data_ptr<scalar_t>(), beta, x.numel());
    }));
    return grad_input;
}
"""

def compile_nova_cuda():
    print("   [JIT Compiler] Compilazione Kernel CUDA in corso (potrebbe richiedere 30-60s)...")
    try:
        nova_ext = load_inline(
            name='nova_cuda_ext',
            cpp_sources=cpp_source,
            cuda_sources=cuda_source,
            functions=['nova_cuda_forward', 'nova_cuda_backward'],
            with_cuda=True,
            extra_cflags=['-O3'],
            extra_cuda_cflags=['-O3', '--use_fast_math']
        )
        print("   [JIT Compiler] Compilazione completata con successo!")
        return nova_ext
    except Exception as e:
        print(f"   [!] Compilazione fallita, fallback su Python Puro: {e}")
        return None

class NOVAFunction(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, beta, nova_ext):
        x = x.contiguous()
        ctx.save_for_backward(x)
        ctx.beta = beta
        ctx.nova_ext = nova_ext
        return nova_ext.nova_cuda_forward(x, beta)

    @staticmethod
    def backward(ctx, grad_output):
        x, = ctx.saved_tensors
        grad_output = grad_output.contiguous()
        grad_x = ctx.nova_ext.nova_cuda_backward(grad_output, x, ctx.beta)
        return grad_x, None, None

class NOVAFusedCUDA(nn.Module):
    def __init__(self, nova_ext, beta=1.0):
        super().__init__()
        self.beta = beta
        self.nova_ext = nova_ext
    def forward(self, x):
        return NOVAFunction.apply(x, self.beta, self.nova_ext)